{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3ab895c1",
   "metadata": {},
   "source": [
    "# Busqueda de parametros para el modelo XGBoost\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ede40ffa",
   "metadata": {},
   "source": [
    "En este notebook se realiza la busqueda de hiperparametros para mejorar las métricas del modelo XGBoost. Para ello se emplean tecnicas de busqueda de hiperparametros como **Optuna** y **RandomizedSearchCV**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f822b216",
   "metadata": {},
   "source": [
    "Se importan las librerias y herramientas necesarias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fa3470e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import preprocessing\n",
    "from sklearn import metrics\n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e116b63c",
   "metadata": {},
   "source": [
    "Importamos los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c7cda726",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle(\"data/data.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "304b2d0c",
   "metadata": {},
   "source": [
    "- A continuación se definen la variable objetivo y las variables independientes\n",
    "- Se definen las columnas numéricas y no numéricas\n",
    "- Se definen las columnas ordinales y categoricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cbcacd66",
   "metadata": {},
   "outputs": [],
   "source": [
    "variable_objetivo = 'naturaleza'\n",
    "variables_independientes = df.drop(variable_objetivo,axis=1).columns\n",
    "\n",
    "datos_numericos = df[variables_independientes].select_dtypes([int, float])\n",
    "col_no_numericas = df[variables_independientes].select_dtypes(include=['category']).columns\n",
    "col_numericas = datos_numericos.columns\n",
    "\n",
    "dict_var_ordinales = {\n",
    "    'grupo_edad': ['0 a 6', '12 a 17', '18 a 28', '29 a 59', '60 y mas', '7  a 11'],\n",
    "    'ciclo_de_vida':['Primera infancia', 'Infancia', 'Jovenes','Adolescencia','Adultez','Persona Mayor'],\n",
    "}\n",
    "\n",
    "col_ordinales = list(dict_var_ordinales.keys())\n",
    "datos_ordinales = df[col_ordinales]\n",
    "col_categoricas = list(set(col_no_numericas) - set(col_ordinales))\n",
    "datos_categoricos = df[col_categoricas]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "266cd1d7",
   "metadata": {},
   "source": [
    "Se importan las librerias necesarias para la creacion del pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6d2ffa17",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.impute import SimpleImputer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "611a74e4",
   "metadata": {},
   "source": [
    "Se mappean los valores de `grupo_edad` y `ciclo_de_vida` y se crea el pipeline_ordinal y posteriormente el pipeline_procesado con las variables categoricas, el pipeline_ordinal y las columnas ordinales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9a94f04f",
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping = [{'col': 'grupo_edad', 'mapping': {'0 a 6': 0,'7  a 11':1 ,'12 a 17': 2, '18 a 28': 3,'29 a 59':4,'60 y mas':5}},    {'col': 'ciclo_de_vida', 'mapping': {'Primera infancia': 0,  'Infancia': 1, 'Jovenes':2 ,'Adolescencia':3,'Adultez':4, 'Persona Mayor':5 }}]\n",
    "from category_encoders import OrdinalEncoder\n",
    "import category_encoders\n",
    "encoder = OrdinalEncoder(mapping=mapping)\n",
    "\n",
    "pipeline_ordinal = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('transformador_ordinal', category_encoders.ordinal.OrdinalEncoder(mapping=mapping))\n",
    "])\n",
    "\n",
    "pipeline_procesado = ColumnTransformer(\n",
    "                   [('onehot', OneHotEncoder(handle_unknown='ignore', sparse_output=False), col_categoricas),\n",
    "                    ('ordinal', pipeline_ordinal, col_ordinales)\n",
    "                   ],\n",
    "                remainder = 'passthrough',\n",
    "                verbose_feature_names_out = False\n",
    "               ).set_output(transform=\"pandas\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d943cd8a",
   "metadata": {},
   "source": [
    " Se establecen los datos de entrenamiento y de prueba para los modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0df8d8d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(df.drop(variable_objetivo, axis=1), df[variable_objetivo], test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c03a4ca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_prep = pipeline_procesado.fit_transform(X_train)\n",
    "X_test_prep  = pipeline_procesado.transform(X_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fcad6829",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.base import clone"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fed4897",
   "metadata": {},
   "source": [
    "### Se define la funcion `evaluar_modelo`, que se encarga de evaluar los diferentes modelos a partir de las metricas obtenidas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "08c42b51",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluar_modelo(clases_reales, predicciones, probabilidades):\n",
    "    exactitudes = []\n",
    "    precisiones = []\n",
    "    sensibilidades = []\n",
    "    f1_scores = []\n",
    "    \n",
    "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    \n",
    "    for train_index, test_index in skf.split(X_train, y_train):\n",
    "        # Se crea una copia del estimador del pipeline\n",
    "        pipeline_estimador_copy = clone(pipeline_estimador)\n",
    "        \n",
    "        # Division de los datos en conjuntos de entrenamiento y prueba\n",
    "        X_train_fold, X_test_fold = X_train.iloc[train_index], X_train.iloc[test_index]\n",
    "        y_train_fold, y_test_fold = y_train.iloc[train_index], y_train.iloc[test_index]\n",
    "        \n",
    "        # Entrenamiento del modelo en el conjunto de entrenamiento actual\n",
    "        pipeline_estimador_copy.fit(X_train_fold, y_train_fold)\n",
    "        \n",
    "        # Se obtienen las predicciones en el conjunto de prueba\n",
    "        predicciones_fold = pipeline_estimador_copy.predict(X_test_fold)\n",
    "        probabilidades_fold = pipeline_estimador_copy.predict_proba(X_test_fold)\n",
    "        \n",
    "        # Calculo de metricas\n",
    "        exactitud = metrics.accuracy_score(y_test_fold, predicciones_fold)\n",
    "        precision = metrics.precision_score(y_test_fold, predicciones_fold, average='macro', zero_division=0)\n",
    "        sensibilidad = metrics.recall_score(y_test_fold, predicciones_fold, average='macro', zero_division=0)\n",
    "        f1 = metrics.f1_score(y_test_fold, predicciones_fold, average='macro', zero_division=0)\n",
    "        \n",
    "        # Se guardan las metricas\n",
    "        exactitudes.append(exactitud)\n",
    "        precisiones.append(precision)\n",
    "        sensibilidades.append(sensibilidad)\n",
    "        f1_scores.append(f1)\n",
    "    \n",
    "    # Calculo de promedios para cada metrica\n",
    "    exactitud_promedio = np.mean(exactitudes)\n",
    "    precision_promedio = np.mean(precisiones)\n",
    "    sensibilidad_promedio = np.mean(sensibilidades)\n",
    "    f1_promedio = np.mean(f1_scores)\n",
    "    \n",
    "    print(\"\"\"\n",
    "    Exactitud promedio: {:.3f}\n",
    "    Precisión promedio: {:.3f}\n",
    "    Sensibilidad promedio: {:.3f}\n",
    "    Puntuación F1 promedio: {:.3f}\n",
    "    \"\"\".format(\n",
    "        exactitud_promedio, \n",
    "        precision_promedio,\n",
    "        sensibilidad_promedio,\n",
    "        f1_promedio\n",
    "    ))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47553591",
   "metadata": {},
   "source": [
    "# XGBoost \n",
    "<hr>\n",
    "\n",
    "### Estado Base: Sin hiperparametros \n",
    "A continuación lo primero que se hace es probar las metricas del modelo en su estado base, es decir, sin configuración de hiperparametros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bc433715",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "575867eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ad5ec033",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_estimador = Pipeline([\n",
    "    (\"procesado_variables\", pipeline_procesado),\n",
    "    (\"estimador\", xgb.XGBClassifier(objective='multi:softmax', num_class=4))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b3c3651c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;procesado_variables&#x27;,\n",
       "                 ColumnTransformer(remainder=&#x27;passthrough&#x27;,\n",
       "                                   transformers=[(&#x27;onehot&#x27;,\n",
       "                                                  OneHotEncoder(handle_unknown=&#x27;ignore&#x27;,\n",
       "                                                                sparse_output=False),\n",
       "                                                  [&#x27;semana&#x27;,\n",
       "                                                   &#x27;tipo_de_seguridad_social&#x27;,\n",
       "                                                   &#x27;año&#x27;,\n",
       "                                                   &#x27;agresor_menor_de_edad&#x27;,\n",
       "                                                   &#x27;departamento&#x27;,\n",
       "                                                   &#x27;violencia_intrafamiliar&#x27;,\n",
       "                                                   &#x27;condicion_final&#x27;,\n",
       "                                                   &#x27;trimestre&#x27;,\n",
       "                                                   &#x27;paciente_hospitalizado&#x27;,\n",
       "                                                   &#x27;sexo_agre&#x27;, &#x27;municipio&#x27;...\n",
       "                               grow_policy=None, importance_type=None,\n",
       "                               interaction_constraints=None, learning_rate=None,\n",
       "                               max_bin=None, max_cat_threshold=None,\n",
       "                               max_cat_to_onehot=None, max_delta_step=None,\n",
       "                               max_depth=None, max_leaves=None,\n",
       "                               min_child_weight=None, missing=nan,\n",
       "                               monotone_constraints=None, n_estimators=100,\n",
       "                               n_jobs=None, num_class=4, num_parallel_tree=None,\n",
       "                               objective=&#x27;multi:softmax&#x27;, ...))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;procesado_variables&#x27;,\n",
       "                 ColumnTransformer(remainder=&#x27;passthrough&#x27;,\n",
       "                                   transformers=[(&#x27;onehot&#x27;,\n",
       "                                                  OneHotEncoder(handle_unknown=&#x27;ignore&#x27;,\n",
       "                                                                sparse_output=False),\n",
       "                                                  [&#x27;semana&#x27;,\n",
       "                                                   &#x27;tipo_de_seguridad_social&#x27;,\n",
       "                                                   &#x27;año&#x27;,\n",
       "                                                   &#x27;agresor_menor_de_edad&#x27;,\n",
       "                                                   &#x27;departamento&#x27;,\n",
       "                                                   &#x27;violencia_intrafamiliar&#x27;,\n",
       "                                                   &#x27;condicion_final&#x27;,\n",
       "                                                   &#x27;trimestre&#x27;,\n",
       "                                                   &#x27;paciente_hospitalizado&#x27;,\n",
       "                                                   &#x27;sexo_agre&#x27;, &#x27;municipio&#x27;...\n",
       "                               grow_policy=None, importance_type=None,\n",
       "                               interaction_constraints=None, learning_rate=None,\n",
       "                               max_bin=None, max_cat_threshold=None,\n",
       "                               max_cat_to_onehot=None, max_delta_step=None,\n",
       "                               max_depth=None, max_leaves=None,\n",
       "                               min_child_weight=None, missing=nan,\n",
       "                               monotone_constraints=None, n_estimators=100,\n",
       "                               n_jobs=None, num_class=4, num_parallel_tree=None,\n",
       "                               objective=&#x27;multi:softmax&#x27;, ...))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">procesado_variables: ColumnTransformer</label><div class=\"sk-toggleable__content\"><pre>ColumnTransformer(remainder=&#x27;passthrough&#x27;,\n",
       "                  transformers=[(&#x27;onehot&#x27;,\n",
       "                                 OneHotEncoder(handle_unknown=&#x27;ignore&#x27;,\n",
       "                                               sparse_output=False),\n",
       "                                 [&#x27;semana&#x27;, &#x27;tipo_de_seguridad_social&#x27;, &#x27;año&#x27;,\n",
       "                                  &#x27;agresor_menor_de_edad&#x27;, &#x27;departamento&#x27;,\n",
       "                                  &#x27;violencia_intrafamiliar&#x27;, &#x27;condicion_final&#x27;,\n",
       "                                  &#x27;trimestre&#x27;, &#x27;paciente_hospitalizado&#x27;,\n",
       "                                  &#x27;sexo_agre&#x27;, &#x27;municipio&#x27;, &#x27;mes&#x27;, &#x27;area&#x27;,\n",
       "                                  &#x27;sexo&#x27;, &#x27;nom_eve&#x27;, &#x27;nom_upg...\n",
       "                                                 (&#x27;transformador_ordinal&#x27;,\n",
       "                                                  OrdinalEncoder(mapping=[{&#x27;col&#x27;: &#x27;grupo_edad&#x27;,\n",
       "                                                                           &#x27;data_type&#x27;: dtype(&#x27;O&#x27;),\n",
       "                                                                           &#x27;mapping&#x27;: 0 a 6       0\n",
       "7  a 11     1\n",
       "12 a 17     2\n",
       "18 a 28     3\n",
       "29 a 59     4\n",
       "60 y mas    5\n",
       "dtype: int64},\n",
       "                                                                          {&#x27;col&#x27;: &#x27;ciclo_de_vida&#x27;,\n",
       "                                                                           &#x27;data_type&#x27;: dtype(&#x27;O&#x27;),\n",
       "                                                                           &#x27;mapping&#x27;: Primera infancia    0\n",
       "Infancia            1\n",
       "Jovenes             2\n",
       "Adolescencia        3\n",
       "Adultez             4\n",
       "Persona Mayor       5\n",
       "dtype: int64}]))]),\n",
       "                                 [&#x27;grupo_edad&#x27;, &#x27;ciclo_de_vida&#x27;])],\n",
       "                  verbose_feature_names_out=False)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">onehot</label><div class=\"sk-toggleable__content\"><pre>[&#x27;semana&#x27;, &#x27;tipo_de_seguridad_social&#x27;, &#x27;año&#x27;, &#x27;agresor_menor_de_edad&#x27;, &#x27;departamento&#x27;, &#x27;violencia_intrafamiliar&#x27;, &#x27;condicion_final&#x27;, &#x27;trimestre&#x27;, &#x27;paciente_hospitalizado&#x27;, &#x27;sexo_agre&#x27;, &#x27;municipio&#x27;, &#x27;mes&#x27;, &#x27;area&#x27;, &#x27;sexo&#x27;, &#x27;nom_eve&#x27;, &#x27;nom_upgd&#x27;, &#x27;victima_menor_de_edad&#x27;, &#x27;parentezco_vict&#x27;, &#x27;sustancias_victima&#x27;, &#x27;comuna&#x27;, &#x27;escenario&#x27;, &#x27;actividad&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">OneHotEncoder</label><div class=\"sk-toggleable__content\"><pre>OneHotEncoder(handle_unknown=&#x27;ignore&#x27;, sparse_output=False)</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">ordinal</label><div class=\"sk-toggleable__content\"><pre>[&#x27;grupo_edad&#x27;, &#x27;ciclo_de_vida&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SimpleImputer</label><div class=\"sk-toggleable__content\"><pre>SimpleImputer(strategy=&#x27;most_frequent&#x27;)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">OrdinalEncoder</label><div class=\"sk-toggleable__content\"><pre>OrdinalEncoder(mapping=[{&#x27;col&#x27;: &#x27;grupo_edad&#x27;, &#x27;data_type&#x27;: dtype(&#x27;O&#x27;),\n",
       "                         &#x27;mapping&#x27;: 0 a 6       0\n",
       "7  a 11     1\n",
       "12 a 17     2\n",
       "18 a 28     3\n",
       "29 a 59     4\n",
       "60 y mas    5\n",
       "dtype: int64},\n",
       "                        {&#x27;col&#x27;: &#x27;ciclo_de_vida&#x27;, &#x27;data_type&#x27;: dtype(&#x27;O&#x27;),\n",
       "                         &#x27;mapping&#x27;: Primera infancia    0\n",
       "Infancia            1\n",
       "Jovenes             2\n",
       "Adolescencia        3\n",
       "Adultez             4\n",
       "Persona Mayor       5\n",
       "dtype: int64}])</pre></div></div></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">remainder</label><div class=\"sk-toggleable__content\"><pre>[&#x27;edad_agre&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">passthrough</label><div class=\"sk-toggleable__content\"><pre>passthrough</pre></div></div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" ><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=100, n_jobs=None, num_class=4,\n",
       "              num_parallel_tree=None, objective=&#x27;multi:softmax&#x27;, ...)</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('procesado_variables',\n",
       "                 ColumnTransformer(remainder='passthrough',\n",
       "                                   transformers=[('onehot',\n",
       "                                                  OneHotEncoder(handle_unknown='ignore',\n",
       "                                                                sparse_output=False),\n",
       "                                                  ['semana',\n",
       "                                                   'tipo_de_seguridad_social',\n",
       "                                                   'año',\n",
       "                                                   'agresor_menor_de_edad',\n",
       "                                                   'departamento',\n",
       "                                                   'violencia_intrafamiliar',\n",
       "                                                   'condicion_final',\n",
       "                                                   'trimestre',\n",
       "                                                   'paciente_hospitalizado',\n",
       "                                                   'sexo_agre', 'municipio'...\n",
       "                               grow_policy=None, importance_type=None,\n",
       "                               interaction_constraints=None, learning_rate=None,\n",
       "                               max_bin=None, max_cat_threshold=None,\n",
       "                               max_cat_to_onehot=None, max_delta_step=None,\n",
       "                               max_depth=None, max_leaves=None,\n",
       "                               min_child_weight=None, missing=nan,\n",
       "                               monotone_constraints=None, n_estimators=100,\n",
       "                               n_jobs=None, num_class=4, num_parallel_tree=None,\n",
       "                               objective='multi:softmax', ...))])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline_estimador.fit(X=X_train, y=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "22875895",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicciones =  pipeline_estimador.predict(X=X_test)\n",
    "clases_reales = y_test\n",
    "predicciones_probabilidades =pipeline_estimador.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "87c58102",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Exactitud promedio: 0.850\n",
      "    Precisión promedio: 0.841\n",
      "    Sensibilidad promedio: 0.839\n",
      "    Puntuación F1 promedio: 0.840\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "evaluar_modelo(clases_reales, predicciones, predicciones_probabilidades)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "58cc4156",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy en datos de entrenamiento: 0.9587333112655854\n",
      "Accuracy en datos de prueba: 0.8468667255075022\n"
     ]
    }
   ],
   "source": [
    "train_accuracy = accuracy_score(y_train, pipeline_estimador.predict(X_train))\n",
    "test_accuracy = accuracy_score(y_test, pipeline_estimador.predict(X_test))\n",
    "print(\"Accuracy en datos de entrenamiento:\", train_accuracy)\n",
    "print(\"Accuracy en datos de prueba:\", test_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee9fb4fd",
   "metadata": {},
   "source": [
    "<hr> \n",
    "\n",
    "# SEGUNDA PARTE: Busqueda de hiperparametros\n",
    "\n",
    "<hr> \n",
    "\n",
    "A continuación se presentan las configuraciones de hiperparametros que se probaron para obtener los mejores hiperparametros para el modelo XGBoost. Después de encontrar los hiperparametros, estos eran evaluados a traves de las metricas obtenidas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ac7b24cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "047b493d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    # Se define un conjunto de hiperparametros con su rango\n",
    "    params = {\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.1),\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 8),\n",
    "        'min_child_weight': trial.suggest_float('min_child_weight', 0.1, 10.0),\n",
    "        'subsample': trial.suggest_float('subsample', 0.5, 0.8),\n",
    "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 0.8),\n",
    "        'reg_alpha': trial.suggest_float('reg_alpha', 0.001, 0.1),\n",
    "        'reg_lambda': trial.suggest_float('reg_lambda', 0.001, 0.1),\n",
    "        'gamma': trial.suggest_float('gamma', 0.1, 1.0),\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 100, 500),\n",
    "        'objective': 'multi:softmax',\n",
    "        'num_class': 4\n",
    "    }\n",
    "\n",
    "    # Crear un objeto XGBClassifier con los hiperparámetros sugeridos por Optuna\n",
    "    estimator = xgb.XGBClassifier(**params)\n",
    "\n",
    "    # Crear un nuevo pipeline que incluya el pipeline_procesado y el estimador \n",
    "    pipeline = Pipeline([\n",
    "        (\"procesado_variables\", pipeline_procesado),\n",
    "        (\"estimador\", estimator)\n",
    "    ])\n",
    "\n",
    "    # Entrenar el pipeline con los datos de entrenamiento\n",
    "    pipeline.fit(X_train, y_train)\n",
    "\n",
    "    # Calcular el puntaje de precisión en el conjunto de prueba\n",
    "    y_pred = pipeline.predict(X_test)\n",
    "    score = accuracy_score(y_test, y_pred)\n",
    "\n",
    "    return score\n",
    "\n",
    "# Crear el estudio de Optuna y ejecutar la optimización\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=100)\n",
    "\n",
    "# Obtener los mejores hiperparámetros encontrados\n",
    "best_params = study.best_trial.params\n",
    "print(\"Mejores hiperparámetros encontrados:\", best_params)\n",
    "\n",
    "# Crear un nuevo objeto XGBClassifier con los mejores hiperparámetros\n",
    "best_estimator = xgb.XGBClassifier(**best_params)\n",
    "\n",
    "# Crear un nuevo pipeline que incluya el preprocesamiento y el estimador con los mejores hiperparámetros\n",
    "new_pipeline = Pipeline([\n",
    "    (\"procesado_variables\", pipeline_procesado),\n",
    "    (\"estimador\", best_estimator)\n",
    "])\n",
    "\n",
    "# Entrenar y evaluar el nuevo pipeline con los mejores hiperparámetros\n",
    "new_pipeline.fit(X_train, y_train)\n",
    "score = new_pipeline.score(X_test, y_test)\n",
    "print(\"Exactitud del modelo con los mejores hiperparámetros:\", score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1513c750",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicciones =  new_pipeline.predict(X=X_test)\n",
    "clases_reales = y_test\n",
    "predicciones_probabilidades =new_pipeline.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dd349a24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Exactitud promedio: 0.849\n",
      "    Precisión promedio: 0.841\n",
      "    Sensibilidad promedio: 0.839\n",
      "    Puntuación F1 promedio: 0.840\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "evaluar_modelo(clases_reales, predicciones, predicciones_probabilidades)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "75225f29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy en datos de entrenamiento: 0.9452719849939314\n",
      "Accuracy en datos de prueba: 0.8578993821712269\n"
     ]
    }
   ],
   "source": [
    "train_accuracy = accuracy_score(y_train, new_pipeline.predict(X_train))\n",
    "test_accuracy = accuracy_score(y_test, new_pipeline.predict(X_test))\n",
    "print(\"Accuracy en datos de entrenamiento:\", train_accuracy)\n",
    "print(\"Accuracy en datos de prueba:\", test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "872276a0",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    params = {\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.05),\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 6),\n",
    "        'min_child_weight': trial.suggest_float('min_child_weight', 0.5, 5.0),\n",
    "        'subsample': trial.suggest_float('subsample', 0.6, 0.8),\n",
    "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.6, 0.8),\n",
    "        'reg_alpha': trial.suggest_float('reg_alpha', 0.001, 0.01),\n",
    "        'reg_lambda': trial.suggest_float('reg_lambda', 0.001, 0.01),\n",
    "        'gamma': trial.suggest_float('gamma', 0.1, 0.5),\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 200, 500),\n",
    "        'objective': 'multi:softmax',\n",
    "        'num_class': 4\n",
    "    }\n",
    "\n",
    "    # Crear un objeto XGBClassifier con los hiperparámetros sugeridos por Optuna\n",
    "    estimator = xgb.XGBClassifier(**params)\n",
    "\n",
    "    # Crear un nuevo pipeline que incluya el pipeline_procesado y el estimador\n",
    "    pipeline = Pipeline([\n",
    "        (\"procesado_variables\", pipeline_procesado),\n",
    "        (\"estimador\", estimator)\n",
    "    ])\n",
    "\n",
    "    # Entrenar el pipeline con los datos de entrenamiento\n",
    "    pipeline.fit(X_train, y_train)\n",
    "\n",
    "    # Calcular el puntaje de precisión en el conjunto de prueba\n",
    "    y_pred = pipeline.predict(X_test)\n",
    "    score = accuracy_score(y_test, y_pred)\n",
    "\n",
    "    return score\n",
    "\n",
    "# Crear el estudio de Optuna y ejecutar la optimización\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=100)\n",
    "\n",
    "# Obtener los mejores hiperparámetros encontrados\n",
    "best_params = study.best_trial.params\n",
    "print(\"Mejores hiperparámetros encontrados:\", best_params)\n",
    "\n",
    "# Crear un nuevo objeto XGBClassifier con los mejores hiperparámetros\n",
    "best_estimator = xgb.XGBClassifier(**best_params)\n",
    "\n",
    "# Crear un nuevo pipeline que incluya el pipeline_procesado y el estimador con los mejores hiperparámetros\n",
    "new_pipeline = Pipeline([\n",
    "    (\"procesado_variables\", pipeline_procesado),\n",
    "    (\"estimador\", best_estimator)\n",
    "])\n",
    "\n",
    "# Entrenar y evaluar el nuevo pipeline con los mejores hiperparámetros\n",
    "new_pipeline.fit(X_train, y_train)\n",
    "score = new_pipeline.score(X_test, y_test)\n",
    "print(\"Exactitud del modelo con los mejores hiperparámetros:\", score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8b53579e",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicciones =  new_pipeline.predict(X=X_test)\n",
    "clases_reales = y_test\n",
    "predicciones_probabilidades =new_pipeline.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d75852bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Exactitud promedio: 0.849\n",
      "    Precisión promedio: 0.841\n",
      "    Sensibilidad promedio: 0.839\n",
      "    Puntuación F1 promedio: 0.840\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "evaluar_modelo(clases_reales, predicciones, predicciones_probabilidades)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b75d7654",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy en datos de entrenamiento: 0.9171356063113759\n",
      "Accuracy en datos de prueba: 0.8583406884377758\n"
     ]
    }
   ],
   "source": [
    "train_accuracy = accuracy_score(y_train, new_pipeline.predict(X_train))\n",
    "test_accuracy = accuracy_score(y_test, new_pipeline.predict(X_test))\n",
    "print(\"Accuracy en datos de entrenamiento:\", train_accuracy)\n",
    "print(\"Accuracy en datos de prueba:\", test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c77dfad",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    params = {\n",
    "        'objective': 'multi:softmax',\n",
    "        'num_class': 4,\n",
    "        'verbosity': 0,\n",
    "        'eval_metric': 'mlogloss',\n",
    "        'booster': trial.suggest_categorical('booster', ['gbtree', 'gblinear', 'dart']),\n",
    "        'lambda': trial.suggest_float('lambda', 1e-8, 1.0, log=True),\n",
    "        'alpha': trial.suggest_float('alpha', 1e-8, 1.0, log=True),\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 9),\n",
    "        'eta': trial.suggest_float('eta', 0.01, 1.0, log=True),\n",
    "        'gamma': trial.suggest_float('gamma', 1e-8, 1.0, log=True),\n",
    "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.1, 1.0),\n",
    "        'min_child_weight': trial.suggest_int('min_child_weight', 1, 10),\n",
    "    }\n",
    "\n",
    "    # Crear un objeto XGBClassifier con los hiperparámetros sugeridos por Optuna\n",
    "    estimator = xgb.XGBClassifier(**params)\n",
    "\n",
    "    # Crear un nuevo pipeline que incluya el pipeline_procesado y el estimador\n",
    "    pipeline = Pipeline([\n",
    "        (\"procesado_variables\", pipeline_procesado),\n",
    "        (\"estimador\", estimator)\n",
    "    ])\n",
    "\n",
    "    # Entrenar el pipeline con los datos de entrenamiento\n",
    "    pipeline.fit(X_train, y_train)\n",
    "\n",
    "    # Calcular el puntaje de precisión en el conjunto de prueba\n",
    "    y_pred = pipeline.predict(X_test)\n",
    "    score = accuracy_score(y_test, y_pred)\n",
    "\n",
    "    return score\n",
    "\n",
    "# Crear el estudio de Optuna y ejecutar la optimización\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=100)\n",
    "\n",
    "# Obtener los mejores hiperparámetros encontrados\n",
    "best_params = study.best_trial.params\n",
    "print(\"Mejores hiperparámetros encontrados:\", best_params)\n",
    "\n",
    "# Crear un nuevo objeto XGBClassifier con los mejores hiperparámetros\n",
    "best_estimator = xgb.XGBClassifier(**best_params)\n",
    "\n",
    "# Crear un nuevo pipeline que incluya el pipeline_procesado y el estimador con los mejores hiperparámetros\n",
    "new_pipeline = Pipeline([\n",
    "    (\"procesado_variables\", pipeline_procesado),\n",
    "    (\"estimador\", best_estimator)\n",
    "])\n",
    "\n",
    "# Entrenar y evaluar el nuevo pipeline con los mejores hiperparámetros\n",
    "new_pipeline.fit(X_train, y_train)\n",
    "score = new_pipeline.score(X_test, y_test)\n",
    "print(\"Exactitud del modelo con los mejores hiperparámetros:\", score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "dfa18bc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicciones =  new_pipeline.predict(X=X_test)\n",
    "clases_reales = y_test\n",
    "predicciones_probabilidades =new_pipeline.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3cc6852c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Exactitud promedio: 0.849\n",
      "    Precisión promedio: 0.841\n",
      "    Sensibilidad promedio: 0.839\n",
      "    Puntuación F1 promedio: 0.840\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "evaluar_modelo(clases_reales, predicciones, predicciones_probabilidades)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9556b2df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy en datos de entrenamiento: 0.9308176100628931\n",
      "Accuracy en datos de prueba: 0.8592233009708737\n"
     ]
    }
   ],
   "source": [
    "train_accuracy = accuracy_score(y_train, new_pipeline.predict(X_train))\n",
    "test_accuracy = accuracy_score(y_test, new_pipeline.predict(X_test))\n",
    "print(\"Accuracy en datos de entrenamiento:\", train_accuracy)\n",
    "print(\"Accuracy en datos de prueba:\", test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0c0dec04",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "def buscar_mejores_hiperparametros(pipeline, X_train, y_train):\n",
    "    parametros = {\n",
    "        'estimador__learning_rate': [0.1, 0.05, 0.01],\n",
    "        'estimador__max_depth': [3, 4, 5],\n",
    "        'estimador__min_child_weight': [1, 2, 3],\n",
    "        'estimador__gamma': [0, 0.1, 0.2],\n",
    "        'estimador__subsample': [0.8, 0.9, 1.0],\n",
    "        'estimador__colsample_bytree': [0.6, 0.7, 0.8],\n",
    "        'estimador__reg_alpha': [0, 0.1, 0.5],\n",
    "        'estimador__reg_lambda': [0, 0.1, 0.5],\n",
    "        'estimador__scale_pos_weight': [1, 2, 3]\n",
    "    }\n",
    "    # Crear el objeto RandomizedSearchCV\n",
    "    busqueda = RandomizedSearchCV(pipeline, parametros, scoring='accuracy', n_iter=10, cv=5)\n",
    "\n",
    "    # Realizar la búsqueda de hiperparámetros\n",
    "    busqueda.fit(X_train, y_train)\n",
    "\n",
    "    # Obtener los mejores hiperparámetros encontrados\n",
    "    mejores_hiperparametros = busqueda.best_params_\n",
    "\n",
    "    # Crear un nuevo pipeline con los mejores hiperparámetros encontrados\n",
    "    nuevo_pipeline = Pipeline([\n",
    "        (\"procesado_variables\", pipeline.named_steps['procesado_variables']),\n",
    "        (\"estimador\", xgb.XGBClassifier(objective='multi:softmax', num_class=4, **mejores_hiperparametros))\n",
    "    ])\n",
    "\n",
    "    # Entrenar el nuevo pipeline con el conjunto de datos de entrenamiento\n",
    "    nuevo_pipeline.fit(X_train, y_train)\n",
    "\n",
    "    # Calcular la exactitud obtenida con los mejores hiperparámetros\n",
    "    exactitud = nuevo_pipeline.score(X_train, y_train)\n",
    "\n",
    "    # Imprimir los mejores hiperparámetros encontrados y la exactitud obtenida\n",
    "    print(\"Mejores hiperparámetros encontrados:\", mejores_hiperparametros)\n",
    "    print(\"Exactitud obtenida:\", exactitud)\n",
    "\n",
    "    # Devolver el nuevo pipeline entrenado\n",
    "    return nuevo_pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "abaf54f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_estimador = Pipeline([\n",
    "    (\"procesado_variables\", pipeline_procesado),\n",
    "    (\"estimador\", xgb.XGBClassifier(objective='multi:softmax', num_class=4))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eace85ec",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "nuevo_pipeline = buscar_mejores_hiperparametros(pipeline_estimador, X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "82d72c99",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicciones =  nuevo_pipeline.predict(X=X_test)\n",
    "clases_reales = y_test\n",
    "predicciones_probabilidades =nuevo_pipeline.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5c8edf82",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Exactitud promedio: 0.849\n",
      "    Precisión promedio: 0.841\n",
      "    Sensibilidad promedio: 0.839\n",
      "    Puntuación F1 promedio: 0.840\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "evaluar_modelo(clases_reales, predicciones, predicciones_probabilidades)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "508c48ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy en datos de entrenamiento: 0.9579609400860642\n",
      "Accuracy en datos de prueba: 0.8442188879082083\n"
     ]
    }
   ],
   "source": [
    "train_accuracy = accuracy_score(y_train, nuevo_pipeline.predict(X_train))\n",
    "test_accuracy = accuracy_score(y_test, nuevo_pipeline.predict(X_test))\n",
    "print(\"Accuracy en datos de entrenamiento:\", train_accuracy)\n",
    "print(\"Accuracy en datos de prueba:\", test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06b1477f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    params = {\n",
    "        'estimador__learning_rate': trial.suggest_loguniform('estimador__learning_rate', 0.001, 0.1),\n",
    "        'estimador__max_depth': trial.suggest_int('estimador__max_depth', 3, 10),\n",
    "        'estimador__subsample': trial.suggest_uniform('estimador__subsample', 0.5, 1.0),\n",
    "        'estimador__colsample_bytree': trial.suggest_uniform('estimador__colsample_bytree', 0.5, 1.0),\n",
    "        'estimador__reg_alpha': trial.suggest_loguniform('estimador__reg_alpha', 1e-10, 1.0),\n",
    "        'estimador__reg_lambda': trial.suggest_loguniform('estimador__reg_lambda', 1e-10, 1.0),\n",
    "        'estimador__n_estimators': trial.suggest_int('estimador__n_estimators', 100, 1000),\n",
    "        'estimador__min_child_weight': trial.suggest_int('estimador__min_child_weight', 1, 10),\n",
    "    }\n",
    "\n",
    "    # Crear el pipeline con los hiperparámetros sugeridos por Optuna\n",
    "    pipeline_estimador = Pipeline([\n",
    "        (\"procesado_variables\", pipeline_procesado),\n",
    "        (\"estimador\", xgb.XGBClassifier(**params))\n",
    "    ])\n",
    "\n",
    "    # Ajustar el pipeline al conjunto de entrenamiento\n",
    "    pipeline_estimador.fit(X_train, y_train)\n",
    "\n",
    "    # Realizar predicciones en los datos de entrenamiento\n",
    "    predicciones_entrenamiento = pipeline_estimador.predict(X_train)\n",
    "\n",
    "    # Calcular las métricas de evaluación en los datos de entrenamiento\n",
    "    accuracy_entrenamiento = accuracy_score(y_train, predicciones_entrenamiento)\n",
    "    precision_entrenamiento = precision_score(y_train, predicciones_entrenamiento, average='macro')\n",
    "    recall_entrenamiento = recall_score(y_train, predicciones_entrenamiento, average='macro')\n",
    "    f1_entrenamiento = f1_score(y_train, predicciones_entrenamiento, average='macro')\n",
    "\n",
    "    # Realizar predicciones en los datos de prueba\n",
    "    predicciones_prueba = pipeline_estimador.predict(X_test)\n",
    "\n",
    "    # Calcular las métricas de evaluación en los datos de prueba\n",
    "    accuracy_prueba = accuracy_score(y_test, predicciones_prueba)\n",
    "    precision_prueba = precision_score(y_test, predicciones_prueba, average='macro')\n",
    "    recall_prueba = recall_score(y_test, predicciones_prueba, average='macro')\n",
    "    f1_prueba = f1_score(y_test, predicciones_prueba, average='macro')\n",
    "\n",
    "    # Imprimir las métricas de evaluación en los datos de entrenamiento y de prueba\n",
    "    print(\"ENTRENAMIENTO\")\n",
    "    print(\"Accuracy en datos de entrenamiento:\", accuracy_entrenamiento)\n",
    "    print(\"Precision en datos de entrenamiento:\", precision_entrenamiento)\n",
    "    print(\"Recall en datos de entrenamiento:\", recall_entrenamiento)\n",
    "    print(\"F1-score en datos de entrenamiento:\", f1_entrenamiento)\n",
    "    print(\"PRUEBA\")\n",
    "    print(\"Accuracy en datos de prueba:\", accuracy_prueba)\n",
    "    print(\"Precision en datos de prueba:\", precision_prueba)\n",
    "    print(\"Recall en datos de prueba:\", recall_prueba)\n",
    "    print(\"F1-score en datos de prueba:\", f1_prueba)\n",
    "\n",
    "    # Calcular la métrica a optimizar utilizando validación cruzada\n",
    "    metrica = cross_val_score(pipeline_estimador, X_train, y_train, scoring='accuracy', cv=5).mean()\n",
    "\n",
    "    # Devolver la métrica para ser maximizada por Optuna\n",
    "    return metrica\n",
    "\n",
    "# Crear un estudio de Optuna\n",
    "study = optuna.create_study(direction='maximize')\n",
    "\n",
    "# Ejecutar la optimización de hiperparámetros\n",
    "study.optimize(objective, n_trials=100)\n",
    "\n",
    "# Obtener los mejores hiperparámetros encontrados\n",
    "mejores_hiperparametros = study.best_params\n",
    "metrica_maxima = study.best_value\n",
    "\n",
    "# Imprimir los mejores hiperparámetros y la métrica máxima obtenida\n",
    "print(\"Mejores hiperparámetros encontrados:\", mejores_hiperparametros)\n",
    "print(\"Métrica máxima obtenida:\", metrica_maxima)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93b6a001",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    params = {\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.0001, 0.1, log=True),\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 10),\n",
    "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 1.0),\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 100, 1000),\n",
    "        'reg_alpha': trial.suggest_float('reg_alpha', 1e-10, 1.0, log=True),\n",
    "        'reg_lambda': trial.suggest_float('reg_lambda', 1e-10, 1.0, log=True),\n",
    "        'min_child_weight': trial.suggest_int('min_child_weight', 1, 10),\n",
    "        'gamma': trial.suggest_float('gamma', 1e-10, 1.0, log=True),\n",
    "        'subsample': trial.suggest_float('subsample', 0.5, 1.0)\n",
    "    }\n",
    "\n",
    "\n",
    "    # Crear el pipeline con los hiperparámetros sugeridos por Optuna\n",
    "    pipeline_estimador = Pipeline([\n",
    "        (\"procesado_variables\", pipeline_procesado),\n",
    "        (\"estimador\", xgb.XGBClassifier(**params))\n",
    "    ])\n",
    "\n",
    "    # Ajustar el pipeline al conjunto de entrenamiento\n",
    "    pipeline_estimador.fit(X_train, y_train)\n",
    "\n",
    "    # Realizar predicciones en los datos de entrenamiento\n",
    "    predicciones_entrenamiento = pipeline_estimador.predict(X_train)\n",
    "\n",
    "    # Calcular las métricas de evaluación en los datos de entrenamiento\n",
    "    accuracy_entrenamiento = accuracy_score(y_train, predicciones_entrenamiento)\n",
    "    precision_entrenamiento = precision_score(y_train, predicciones_entrenamiento, average='macro')\n",
    "    recall_entrenamiento = recall_score(y_train, predicciones_entrenamiento, average='macro')\n",
    "    f1_entrenamiento = f1_score(y_train, predicciones_entrenamiento, average='macro')\n",
    "\n",
    "    # Realizar predicciones en los datos de prueba\n",
    "    predicciones_prueba = pipeline_estimador.predict(X_test)\n",
    "\n",
    "    # Calcular las métricas de evaluación en los datos de prueba\n",
    "    accuracy_prueba = accuracy_score(y_test, predicciones_prueba)\n",
    "    precision_prueba = precision_score(y_test, predicciones_prueba, average='macro')\n",
    "    recall_prueba = recall_score(y_test, predicciones_prueba, average='macro')\n",
    "    f1_prueba = f1_score(y_test, predicciones_prueba, average='macro')\n",
    "\n",
    "    # Imprimir las métricas de evaluación en los datos de entrenamiento y de prueba\n",
    "    print(\"ENTRENAMIENTO\")\n",
    "    print(\"Accuracy en datos de entrenamiento:\", accuracy_entrenamiento)\n",
    "    print(\"Precision en datos de entrenamiento:\", precision_entrenamiento)\n",
    "    print(\"Recall en datos de entrenamiento:\", recall_entrenamiento)\n",
    "    print(\"F1-score en datos de entrenamiento:\", f1_entrenamiento)\n",
    "    print(\"PRUEBA\")\n",
    "    print(\"Accuracy en datos de prueba:\", accuracy_prueba)\n",
    "    print(\"Precision en datos de prueba:\", precision_prueba)\n",
    "    print(\"Recall en datos de prueba:\", recall_prueba)\n",
    "    print(\"F1-score en datos de prueba:\", f1_prueba)\n",
    "\n",
    "    # Calcular la métrica a optimizar utilizando validación cruzada\n",
    "    metrica = cross_val_score(pipeline_estimador, X_train, y_train, scoring='accuracy', cv=5).mean()\n",
    "\n",
    "    # Devolver la métrica para ser maximizada por Optuna\n",
    "    return metrica\n",
    "\n",
    "# Crear un estudio de Optuna\n",
    "study = optuna.create_study(direction='maximize')\n",
    "\n",
    "# Ejecutar la optimización de hiperparámetros\n",
    "study.optimize(objective, n_trials=100)\n",
    "\n",
    "# Obtener los mejores hiperparámetros encontrados\n",
    "mejores_hiperparametros = study.best_params\n",
    "metrica_maxima = study.best_value\n",
    "\n",
    "# Imprimir los mejores hiperparámetros y la métrica máxima obtenida\n",
    "print(\"Mejores hiperparámetros encontrados:\", mejores_hiperparametros)\n",
    "print(\"Métrica máxima obtenida:\", metrica_maxima)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3734a83",
   "metadata": {},
   "source": [
    "### Finalmente, los mejores hiperparametros obtenidos son guardados en otro notebook donde se almacenan y ordenan para encontrar la mejor configuración de hiperparametros para el modelo XGBoost"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
