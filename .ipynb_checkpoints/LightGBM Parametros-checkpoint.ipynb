{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5bfe9595",
   "metadata": {},
   "source": [
    "# Busqueda de parametros para el modelo XGBoost\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a643087c",
   "metadata": {},
   "source": [
    "En este notebook se realiza la busqueda de hiperparametros para mejorar las métricas del modelo XGBoost. Para ello se emplean tecnicas de busqueda de hiperparametros como **Optuna** y **RandomizedSearchCV**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e75a0d9d",
   "metadata": {},
   "source": [
    "Se importan las librerias y herramientas necesarias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0649006b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import preprocessing\n",
    "from sklearn import metrics\n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8d30d2a",
   "metadata": {},
   "source": [
    "Importamos los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "539af26d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle(\"data/data.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc32af1c",
   "metadata": {},
   "source": [
    "- A continuación se definen la variable objetivo y las variables independientes\n",
    "- Se definen las columnas numéricas y no numéricas\n",
    "- Se definen las columnas ordinales y categoricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9a532079",
   "metadata": {},
   "outputs": [],
   "source": [
    "variable_objetivo = 'naturaleza'\n",
    "variables_independientes = df.drop(variable_objetivo,axis=1).columns\n",
    "\n",
    "datos_numericos = df[variables_independientes].select_dtypes([int, float])\n",
    "col_no_numericas = df[variables_independientes].select_dtypes(include=['category']).columns\n",
    "col_numericas = datos_numericos.columns\n",
    "\n",
    "dict_var_ordinales = {\n",
    "    'grupo_edad': ['0 a 6', '12 a 17', '18 a 28', '29 a 59', '60 y mas', '7  a 11'],\n",
    "    'ciclo_de_vida':['Primera infancia', 'Infancia', 'Jovenes','Adolescencia','Adultez','Persona Mayor'],\n",
    "}\n",
    "\n",
    "col_ordinales = list(dict_var_ordinales.keys())\n",
    "datos_ordinales = df[col_ordinales]\n",
    "col_categoricas = list(set(col_no_numericas) - set(col_ordinales))\n",
    "datos_categoricos = df[col_categoricas]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fe22b40",
   "metadata": {},
   "source": [
    "Se importan las librerias necesarias para la creacion del pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d60d1b4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.impute import SimpleImputer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9d0dc21",
   "metadata": {},
   "source": [
    "Se mappean los valores de `grupo_edad` y `ciclo_de_vida` y se crea el pipeline_ordinal y posteriormente el pipeline_procesado con las variables categoricas, el pipeline_ordinal y las columnas ordinales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "182e8807",
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping = [{'col': 'grupo_edad', 'mapping': {'0 a 6': 0,'7  a 11':1 ,'12 a 17': 2, '18 a 28': 3,'29 a 59':4,'60 y mas':5}},    {'col': 'ciclo_de_vida', 'mapping': {'Primera infancia': 0,  'Infancia': 1, 'Jovenes':2 ,'Adolescencia':3,'Adultez':4, 'Persona Mayor':5 }}]\n",
    "from category_encoders import OrdinalEncoder\n",
    "import category_encoders\n",
    "encoder = OrdinalEncoder(mapping=mapping)\n",
    "\n",
    "pipeline_ordinal = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('transformador_ordinal', category_encoders.ordinal.OrdinalEncoder(mapping=mapping))\n",
    "])\n",
    "\n",
    "pipeline_procesado = ColumnTransformer(\n",
    "                   [('onehot', OneHotEncoder(handle_unknown='ignore', sparse_output=False), col_categoricas),\n",
    "                    ('ordinal', pipeline_ordinal, col_ordinales)\n",
    "                   ],\n",
    "                remainder = 'passthrough',\n",
    "                verbose_feature_names_out = False\n",
    "               ).set_output(transform=\"pandas\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7abf5439",
   "metadata": {},
   "source": [
    "Se establecen los datos de entrenamiento y de prueba para los modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0ed71b31",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(df.drop(variable_objetivo, axis=1), df[variable_objetivo], test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "91973f09",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_prep = pipeline_procesado.fit_transform(X_train)\n",
    "X_test_prep  = pipeline_procesado.transform(X_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "143fa1aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.base import clone"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c56a8c2c",
   "metadata": {},
   "source": [
    "### Se define la funcion `evaluar_modelo`, que se encarga de evaluar los diferentes modelos a partir de las metricas obtenidas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "60a17d10",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluar_modelo(clases_reales, predicciones, probabilidades):\n",
    "    exactitudes = []\n",
    "    precisiones = []\n",
    "    sensibilidades = []\n",
    "    f1_scores = []\n",
    "    \n",
    "    # Create StratifiedKFold object with a fixed random_state\n",
    "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    \n",
    "    # Perform cross-validation\n",
    "    for train_index, test_index in skf.split(X_train, y_train):\n",
    "        # Create a copy of the pipeline estimator\n",
    "        pipeline_estimador_copy = clone(pipeline_estimador)\n",
    "        \n",
    "        # Split the data into train and test sets based on the indices\n",
    "        X_train_fold, X_test_fold = X_train.iloc[train_index], X_train.iloc[test_index]\n",
    "        y_train_fold, y_test_fold = y_train.iloc[train_index], y_train.iloc[test_index]\n",
    "        \n",
    "        # Train the model on the current fold\n",
    "        pipeline_estimador_copy.fit(X_train_fold, y_train_fold)\n",
    "        \n",
    "        # Get predictions in the test set of the current fold\n",
    "        predicciones_fold = pipeline_estimador_copy.predict(X_test_fold)\n",
    "        probabilidades_fold = pipeline_estimador_copy.predict_proba(X_test_fold)\n",
    "        \n",
    "        # Calculate metrics on the current fold\n",
    "        exactitud = metrics.accuracy_score(y_test_fold, predicciones_fold)\n",
    "        precision = metrics.precision_score(y_test_fold, predicciones_fold, average='macro', zero_division=0)\n",
    "        sensibilidad = metrics.recall_score(y_test_fold, predicciones_fold, average='macro', zero_division=0)\n",
    "        f1 = metrics.f1_score(y_test_fold, predicciones_fold, average='macro', zero_division=0)\n",
    "        \n",
    "        # Store metrics of the current fold\n",
    "        exactitudes.append(exactitud)\n",
    "        precisiones.append(precision)\n",
    "        sensibilidades.append(sensibilidad)\n",
    "        f1_scores.append(f1)\n",
    "    \n",
    "    # Calculate averaged metrics\n",
    "    exactitud_promedio = np.mean(exactitudes)\n",
    "    precision_promedio = np.mean(precisiones)\n",
    "    sensibilidad_promedio = np.mean(sensibilidades)\n",
    "    f1_promedio = np.mean(f1_scores)\n",
    "    \n",
    "    # Print averaged metrics\n",
    "    print(\"\"\"\n",
    "    Exactitud promedio: {:.3f}\n",
    "    Precisión promedio: {:.3f}\n",
    "    Sensibilidad promedio: {:.3f}\n",
    "    Puntuación F1 promedio: {:.3f}\n",
    "    \"\"\".format(\n",
    "        exactitud_promedio, \n",
    "        precision_promedio,\n",
    "        sensibilidad_promedio,\n",
    "        f1_promedio\n",
    "    ))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eec7ffa3",
   "metadata": {},
   "source": [
    "# LIGHT\n",
    "<hr>\n",
    "\n",
    "### Estado Base: Sin hiperparametros \n",
    "A continuación lo primero que se hace es probar las metricas del modelo en su estado base, es decir, sin configuración de hiperparametros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ca5da2d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "51943dd8",
   "metadata": {},
   "outputs": [
    {
     "ename": "SystemExit",
     "evalue": "Detener ejecución",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\u001b[1;31m:\u001b[0m Detener ejecución\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pc\\anaconda3\\envs\\data2\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3516: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "raise SystemExit(\"Detener ejecución\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "95ccfd6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_estimador = Pipeline([\n",
    "    (\"procesado_variables\", pipeline_procesado),\n",
    "    (\"estimador\", lgb.LGBMClassifier())  \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d497e1a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;procesado_variables&#x27;,\n",
       "                 ColumnTransformer(remainder=&#x27;passthrough&#x27;,\n",
       "                                   transformers=[(&#x27;onehot&#x27;,\n",
       "                                                  OneHotEncoder(handle_unknown=&#x27;ignore&#x27;,\n",
       "                                                                sparse_output=False),\n",
       "                                                  [&#x27;parentezco_vict&#x27;, &#x27;mes&#x27;,\n",
       "                                                   &#x27;tipo_de_seguridad_social&#x27;,\n",
       "                                                   &#x27;nom_upgd&#x27;, &#x27;area&#x27;,\n",
       "                                                   &#x27;departamento&#x27;, &#x27;comuna&#x27;,\n",
       "                                                   &#x27;sexo_agre&#x27;, &#x27;sexo&#x27;,\n",
       "                                                   &#x27;nom_eve&#x27;, &#x27;municipio&#x27;]),\n",
       "                                                 (&#x27;ordinal&#x27;,\n",
       "                                                  Pipeline(steps=[(&#x27;imputer&#x27;,\n",
       "                                                                   SimpleImput...\n",
       "                                                                   OrdinalEncoder(mapping=[{&#x27;col&#x27;: &#x27;grupo_edad&#x27;,\n",
       "                                                                                            &#x27;data_type&#x27;: dtype(&#x27;O&#x27;),\n",
       "                                                                                            &#x27;mapping&#x27;: 0 a 6       0\n",
       "7  a 11     1\n",
       "12 a 17     2\n",
       "18 a 28     3\n",
       "29 a 59     4\n",
       "60 y mas    5\n",
       "dtype: int64},\n",
       "                                                                                           {&#x27;col&#x27;: &#x27;ciclo_de_vida&#x27;,\n",
       "                                                                                            &#x27;data_type&#x27;: dtype(&#x27;O&#x27;),\n",
       "                                                                                            &#x27;mapping&#x27;: Primera infancia    0\n",
       "Infancia            1\n",
       "Jovenes             2\n",
       "Adolescencia        3\n",
       "Adultez             4\n",
       "Persona Mayor       5\n",
       "dtype: int64}]))]),\n",
       "                                                  [&#x27;grupo_edad&#x27;,\n",
       "                                                   &#x27;ciclo_de_vida&#x27;])],\n",
       "                                   verbose_feature_names_out=False)),\n",
       "                (&#x27;estimador&#x27;, LGBMClassifier())])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;procesado_variables&#x27;,\n",
       "                 ColumnTransformer(remainder=&#x27;passthrough&#x27;,\n",
       "                                   transformers=[(&#x27;onehot&#x27;,\n",
       "                                                  OneHotEncoder(handle_unknown=&#x27;ignore&#x27;,\n",
       "                                                                sparse_output=False),\n",
       "                                                  [&#x27;parentezco_vict&#x27;, &#x27;mes&#x27;,\n",
       "                                                   &#x27;tipo_de_seguridad_social&#x27;,\n",
       "                                                   &#x27;nom_upgd&#x27;, &#x27;area&#x27;,\n",
       "                                                   &#x27;departamento&#x27;, &#x27;comuna&#x27;,\n",
       "                                                   &#x27;sexo_agre&#x27;, &#x27;sexo&#x27;,\n",
       "                                                   &#x27;nom_eve&#x27;, &#x27;municipio&#x27;]),\n",
       "                                                 (&#x27;ordinal&#x27;,\n",
       "                                                  Pipeline(steps=[(&#x27;imputer&#x27;,\n",
       "                                                                   SimpleImput...\n",
       "                                                                   OrdinalEncoder(mapping=[{&#x27;col&#x27;: &#x27;grupo_edad&#x27;,\n",
       "                                                                                            &#x27;data_type&#x27;: dtype(&#x27;O&#x27;),\n",
       "                                                                                            &#x27;mapping&#x27;: 0 a 6       0\n",
       "7  a 11     1\n",
       "12 a 17     2\n",
       "18 a 28     3\n",
       "29 a 59     4\n",
       "60 y mas    5\n",
       "dtype: int64},\n",
       "                                                                                           {&#x27;col&#x27;: &#x27;ciclo_de_vida&#x27;,\n",
       "                                                                                            &#x27;data_type&#x27;: dtype(&#x27;O&#x27;),\n",
       "                                                                                            &#x27;mapping&#x27;: Primera infancia    0\n",
       "Infancia            1\n",
       "Jovenes             2\n",
       "Adolescencia        3\n",
       "Adultez             4\n",
       "Persona Mayor       5\n",
       "dtype: int64}]))]),\n",
       "                                                  [&#x27;grupo_edad&#x27;,\n",
       "                                                   &#x27;ciclo_de_vida&#x27;])],\n",
       "                                   verbose_feature_names_out=False)),\n",
       "                (&#x27;estimador&#x27;, LGBMClassifier())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">procesado_variables: ColumnTransformer</label><div class=\"sk-toggleable__content\"><pre>ColumnTransformer(remainder=&#x27;passthrough&#x27;,\n",
       "                  transformers=[(&#x27;onehot&#x27;,\n",
       "                                 OneHotEncoder(handle_unknown=&#x27;ignore&#x27;,\n",
       "                                               sparse_output=False),\n",
       "                                 [&#x27;parentezco_vict&#x27;, &#x27;mes&#x27;,\n",
       "                                  &#x27;tipo_de_seguridad_social&#x27;, &#x27;nom_upgd&#x27;,\n",
       "                                  &#x27;area&#x27;, &#x27;departamento&#x27;, &#x27;comuna&#x27;, &#x27;sexo_agre&#x27;,\n",
       "                                  &#x27;sexo&#x27;, &#x27;nom_eve&#x27;, &#x27;municipio&#x27;]),\n",
       "                                (&#x27;ordinal&#x27;,\n",
       "                                 Pipeline(steps=[(&#x27;imputer&#x27;,\n",
       "                                                  SimpleImputer(strategy=&#x27;most_frequent&#x27;)),\n",
       "                                                 (&#x27;transformador_ordinal&#x27;,\n",
       "                                                  OrdinalEncoder(mapping=[{&#x27;col&#x27;: &#x27;grupo_edad&#x27;,\n",
       "                                                                           &#x27;data_type&#x27;: dtype(&#x27;O&#x27;),\n",
       "                                                                           &#x27;mapping&#x27;: 0 a 6       0\n",
       "7  a 11     1\n",
       "12 a 17     2\n",
       "18 a 28     3\n",
       "29 a 59     4\n",
       "60 y mas    5\n",
       "dtype: int64},\n",
       "                                                                          {&#x27;col&#x27;: &#x27;ciclo_de_vida&#x27;,\n",
       "                                                                           &#x27;data_type&#x27;: dtype(&#x27;O&#x27;),\n",
       "                                                                           &#x27;mapping&#x27;: Primera infancia    0\n",
       "Infancia            1\n",
       "Jovenes             2\n",
       "Adolescencia        3\n",
       "Adultez             4\n",
       "Persona Mayor       5\n",
       "dtype: int64}]))]),\n",
       "                                 [&#x27;grupo_edad&#x27;, &#x27;ciclo_de_vida&#x27;])],\n",
       "                  verbose_feature_names_out=False)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">onehot</label><div class=\"sk-toggleable__content\"><pre>[&#x27;parentezco_vict&#x27;, &#x27;mes&#x27;, &#x27;tipo_de_seguridad_social&#x27;, &#x27;nom_upgd&#x27;, &#x27;area&#x27;, &#x27;departamento&#x27;, &#x27;comuna&#x27;, &#x27;sexo_agre&#x27;, &#x27;sexo&#x27;, &#x27;nom_eve&#x27;, &#x27;municipio&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">OneHotEncoder</label><div class=\"sk-toggleable__content\"><pre>OneHotEncoder(handle_unknown=&#x27;ignore&#x27;, sparse_output=False)</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">ordinal</label><div class=\"sk-toggleable__content\"><pre>[&#x27;grupo_edad&#x27;, &#x27;ciclo_de_vida&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SimpleImputer</label><div class=\"sk-toggleable__content\"><pre>SimpleImputer(strategy=&#x27;most_frequent&#x27;)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">OrdinalEncoder</label><div class=\"sk-toggleable__content\"><pre>OrdinalEncoder(mapping=[{&#x27;col&#x27;: &#x27;grupo_edad&#x27;, &#x27;data_type&#x27;: dtype(&#x27;O&#x27;),\n",
       "                         &#x27;mapping&#x27;: 0 a 6       0\n",
       "7  a 11     1\n",
       "12 a 17     2\n",
       "18 a 28     3\n",
       "29 a 59     4\n",
       "60 y mas    5\n",
       "dtype: int64},\n",
       "                        {&#x27;col&#x27;: &#x27;ciclo_de_vida&#x27;, &#x27;data_type&#x27;: dtype(&#x27;O&#x27;),\n",
       "                         &#x27;mapping&#x27;: Primera infancia    0\n",
       "Infancia            1\n",
       "Jovenes             2\n",
       "Adolescencia        3\n",
       "Adultez             4\n",
       "Persona Mayor       5\n",
       "dtype: int64}])</pre></div></div></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">remainder</label><div class=\"sk-toggleable__content\"><pre>[&#x27;semana&#x27;, &#x27;año&#x27;, &#x27;paciente_hospitalizado&#x27;, &#x27;condicion_final&#x27;, &#x27;actividad&#x27;, &#x27;edad_agre&#x27;, &#x27;sustancias_victima&#x27;, &#x27;escenario&#x27;, &#x27;sivigila_2012&#x27;, &#x27;sivigila_2014&#x27;, &#x27;sivigila_2015&#x27;, &#x27;sivigila_2016&#x27;, &#x27;sivigila_2017&#x27;, &#x27;sivigila_2018&#x27;, &#x27;trimestre&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">passthrough</label><div class=\"sk-toggleable__content\"><pre>passthrough</pre></div></div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" ><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LGBMClassifier</label><div class=\"sk-toggleable__content\"><pre>LGBMClassifier()</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('procesado_variables',\n",
       "                 ColumnTransformer(remainder='passthrough',\n",
       "                                   transformers=[('onehot',\n",
       "                                                  OneHotEncoder(handle_unknown='ignore',\n",
       "                                                                sparse_output=False),\n",
       "                                                  ['parentezco_vict', 'mes',\n",
       "                                                   'tipo_de_seguridad_social',\n",
       "                                                   'nom_upgd', 'area',\n",
       "                                                   'departamento', 'comuna',\n",
       "                                                   'sexo_agre', 'sexo',\n",
       "                                                   'nom_eve', 'municipio']),\n",
       "                                                 ('ordinal',\n",
       "                                                  Pipeline(steps=[('imputer',\n",
       "                                                                   SimpleImput...\n",
       "                                                                   OrdinalEncoder(mapping=[{'col': 'grupo_edad',\n",
       "                                                                                            'data_type': dtype('O'),\n",
       "                                                                                            'mapping': 0 a 6       0\n",
       "7  a 11     1\n",
       "12 a 17     2\n",
       "18 a 28     3\n",
       "29 a 59     4\n",
       "60 y mas    5\n",
       "dtype: int64},\n",
       "                                                                                           {'col': 'ciclo_de_vida',\n",
       "                                                                                            'data_type': dtype('O'),\n",
       "                                                                                            'mapping': Primera infancia    0\n",
       "Infancia            1\n",
       "Jovenes             2\n",
       "Adolescencia        3\n",
       "Adultez             4\n",
       "Persona Mayor       5\n",
       "dtype: int64}]))]),\n",
       "                                                  ['grupo_edad',\n",
       "                                                   'ciclo_de_vida'])],\n",
       "                                   verbose_feature_names_out=False)),\n",
       "                ('estimador', LGBMClassifier())])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline_estimador.fit(X=X_train, y=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "77ed2334",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicciones =  pipeline_estimador.predict(X=X_test)\n",
    "clases_reales = y_test\n",
    "predicciones_probabilidades =pipeline_estimador.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "02712eff",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Exactitud promedio: 0.824\n",
      "    Precisión promedio: 0.718\n",
      "    Sensibilidad promedio: 0.677\n",
      "    Puntuación F1 promedio: 0.685\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "evaluar_modelo(clases_reales, predicciones, predicciones_probabilidades)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "88b04058",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy en datos de entrenamiento: 0.9305777574788765\n",
      "Accuracy en datos de prueba: 0.8273972602739726\n"
     ]
    }
   ],
   "source": [
    "train_accuracy = accuracy_score(y_train, pipeline_estimador.predict(X_train))\n",
    "test_accuracy = accuracy_score(y_test, pipeline_estimador.predict(X_test))\n",
    "print(\"Accuracy en datos de entrenamiento:\", train_accuracy)\n",
    "print(\"Accuracy en datos de prueba:\", test_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "307cf615",
   "metadata": {},
   "source": [
    "<hr> \n",
    "\n",
    "# SEGUNDA PARTE: Busqueda de hiperparametros\n",
    "\n",
    "<hr> \n",
    "\n",
    "A continuación se presentan las configuraciones de hiperparametros que se probaron para obtener los mejores hiperparametros para el modelo LightGBM. Después de encontrar los hiperparametros, estos eran evaluados a traves de las metricas obtenidas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0305e0cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02b748d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aea70f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objetivo(trial):\n",
    "    # Definir los rangos de los hiperparámetros a buscar\n",
    "    params = {\n",
    "        'boosting_type': trial.suggest_categorical('boosting_type', ['gbdt', 'dart', 'goss']),\n",
    "        'num_leaves': trial.suggest_int('num_leaves', 10, 1000),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.2, log=True),\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 100, 1000),\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 10),\n",
    "        'min_child_samples': trial.suggest_int('min_child_samples', 1, 20),\n",
    "        'subsample': trial.suggest_float('subsample', 0.8, 1.0),\n",
    "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.6, 0.8),\n",
    "        'reg_alpha': trial.suggest_float('reg_alpha', 0.001, 1.0, log=True),\n",
    "        'reg_lambda': trial.suggest_float('reg_lambda', 0.001, 1.0, log=True),\n",
    "        'objective': 'multiclass',\n",
    "        'num_class': 4,\n",
    "        'is_unbalance': True,\n",
    "    }\n",
    "\n",
    "    # Crear el modelo con los hiperparámetros propuestos\n",
    "    estimador = lgb.LGBMClassifier(**params)\n",
    "    \n",
    "    pipeline = Pipeline([\n",
    "        (\"procesado_variables\", pipeline_procesado),\n",
    "        (\"estimador\", estimador)\n",
    "    ])\n",
    "\n",
    "    # Entrenar y evaluar el modelo con validación cruzada\n",
    "    score = cross_val_score(pipeline, X_train, y_train, scoring='accuracy', cv=5).mean()\n",
    "\n",
    "    return score\n",
    "\n",
    "# Crear el estudio de Optuna\n",
    "estudio = optuna.create_study(direction='maximize')\n",
    "\n",
    "# Ejecutar la búsqueda de hiperparámetros\n",
    "estudio.optimize(objetivo, n_trials=100)\n",
    "\n",
    "# Obtener los mejores hiperparámetros encontrados\n",
    "mejores_hiperparametros = estudio.best_params\n",
    "\n",
    "# Imprimir los mejores hiperparámetros encontrados\n",
    "print(\"Mejores hiperparámetros encontrados:\", mejores_hiperparametros)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0739fe30",
   "metadata": {},
   "outputs": [],
   "source": [
    "def buscar_mejores_hiperparametros(pipeline, X_train, y_train):\n",
    "    # Definir los posibles valores de los hiperparámetros a buscar\n",
    "    parametros = {\n",
    "        'estimador__boosting_type': ['gbdt', 'dart', 'goss'],\n",
    "        'estimador__num_leaves': [20, 30, 40, 50],\n",
    "        'estimador__learning_rate': [0.01, 0.05, 0.1, 0.2],\n",
    "        'estimador__n_estimators': [100, 200, 300, 400],\n",
    "        'estimador__max_depth': [3, 5, 7, 9],\n",
    "        'estimador__min_child_samples': [10, 20, 30, 40],\n",
    "        'estimador__subsample': [0.8, 0.9, 1.0],\n",
    "        'estimador__colsample_bytree': [0.6, 0.7, 0.8]\n",
    "    }\n",
    "    # Crear el objeto RandomizedSearchCV\n",
    "    busqueda = RandomizedSearchCV(pipeline, parametros, scoring='accuracy', n_iter=10, cv=5)\n",
    "\n",
    "    # Realizar la búsqueda de hiperparámetros\n",
    "    busqueda.fit(X_train, y_train)\n",
    "\n",
    "    # Obtener los mejores hiperparámetros encontrados\n",
    "    mejores_hiperparametros = busqueda.best_params_\n",
    "\n",
    "    # Crear un nuevo pipeline con los mejores hiperparámetros encontrados\n",
    "    nuevo_pipeline = Pipeline([\n",
    "        (\"procesado_variables\", pipeline.named_steps['procesado_variables']),\n",
    "        (\"estimador\", lgb.LGBMClassifier(objective='multiclass', num_class=4, **mejores_hiperparametros))\n",
    "    ])\n",
    "\n",
    "    # Entrenar el nuevo pipeline con el conjunto de datos de entrenamiento\n",
    "    nuevo_pipeline.fit(X_train, y_train)\n",
    "\n",
    "    # Calcular la exactitud obtenida con los mejores hiperparámetros\n",
    "    exactitud = nuevo_pipeline.score(X_train, y_train)\n",
    "\n",
    "    # Imprimir los mejores hiperparámetros encontrados y la exactitud obtenida\n",
    "    print(\"Mejores hiperparámetros encontrados:\", mejores_hiperparametros)\n",
    "    print(\"Exactitud obtenida:\", exactitud)\n",
    "\n",
    "    # Devolver el nuevo pipeline entrenado\n",
    "    return nuevo_pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d75f92e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "nuevo_pipeline = buscar_mejores_hiperparametros(pipeline_estimador, X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4c3930d",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicciones =  nuevo_pipeline.predict(X=X_test)\n",
    "clases_reales = y_test\n",
    "predicciones_probabilidades =nuevo_pipeline.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c4cfe1b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "evaluar_modelo(clases_reales, predicciones, predicciones_probabilidades)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aa4b7f5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_accuracy = accuracy_score(y_train, nuevo_pipeline.predict(X_train))\n",
    "test_accuracy = accuracy_score(y_test, nuevo_pipeline.predict(X_test))\n",
    "print(\"Accuracy en datos de entrenamiento:\", train_accuracy)\n",
    "print(\"Accuracy en datos de prueba:\", test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e25fe87",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_estimador = Pipeline([\n",
    "    (\"procesado_variables\", pipeline_procesado),\n",
    "    (\"estimador\", lgb.LGBMClassifier(**hiperparametros))  \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09c731c9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pipeline_estimador.fit(X=X_train, y=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "283b3ea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicciones =  pipeline_estimador.predict(X=X_test)\n",
    "clases_reales = y_test\n",
    "predicciones_probabilidades =pipeline_estimador.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "526e7f16",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "evaluar_modelo(clases_reales, predicciones, predicciones_probabilidades)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75ffb391",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_accuracy = accuracy_score(y_train, pipeline_estimador.predict(X_train))\n",
    "test_accuracy = accuracy_score(y_test, pipeline_estimador.predict(X_test))\n",
    "print(\"Accuracy en datos de entrenamiento:\", train_accuracy)\n",
    "print(\"Accuracy en datos de prueba:\", test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "857b3956",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    # Definir los rangos de búsqueda de los hiperparámetros\n",
    "    params = {\n",
    "        'estimador__learning_rate': trial.suggest_float('estimador__learning_rate', 0.01, 0.1, log=True),\n",
    "        'estimador__reg_alpha': trial.suggest_float('estimador__reg_alpha', 1e-10, 1.0, log=True),\n",
    "        'estimador__reg_lambda': trial.suggest_float('estimador__reg_lambda', 1e-10, 1.0, log=True),\n",
    "        'estimador__num_leaves': trial.suggest_int('estimador__num_leaves', 20, 200),\n",
    "        'estimador__max_depth': trial.suggest_int('estimador__max_depth', 3, 10),\n",
    "        'estimador__min_child_samples': trial.suggest_int('estimador__min_child_samples', 1, 20),\n",
    "        'estimador__subsample': trial.suggest_float('estimador__subsample', 0.5, 1.0),\n",
    "        'estimador__colsample_bytree': trial.suggest_float('estimador__colsample_bytree', 0.5, 1.0),\n",
    "        'estimador__n_estimators': trial.suggest_int('estimador__n_estimators', 100, 1000),\n",
    "        'estimador__scale_pos_weight': trial.suggest_float('estimador__scale_pos_weight', 0.1, 10.0)\n",
    "    }\n",
    "\n",
    "    # Crear el pipeline con los hiperparámetros sugeridos por Optuna\n",
    "    pipeline_estimador = Pipeline([\n",
    "        (\"procesado_variables\", pipeline_procesado),\n",
    "        (\"estimador\", lgb.LGBMClassifier(**params))\n",
    "    ])\n",
    "\n",
    "    # Ajustar el pipeline al conjunto de entrenamiento\n",
    "    pipeline_estimador.fit(X_train, y_train)\n",
    "\n",
    "    # Realizar predicciones en los datos de entrenamiento\n",
    "    predicciones_entrenamiento = pipeline_estimador.predict(X_train)\n",
    "\n",
    "    # Calcular las métricas de evaluación en los datos de entrenamiento\n",
    "    accuracy_entrenamiento = accuracy_score(y_train, predicciones_entrenamiento)\n",
    "    precision_entrenamiento = precision_score(y_train, predicciones_entrenamiento, average='macro')\n",
    "    recall_entrenamiento = recall_score(y_train, predicciones_entrenamiento, average='macro')\n",
    "    f1_entrenamiento = f1_score(y_train, predicciones_entrenamiento, average='macro')\n",
    "\n",
    "    # Realizar predicciones en los datos de prueba\n",
    "    predicciones_prueba = pipeline_estimador.predict(X_test)\n",
    "\n",
    "    # Calcular las métricas de evaluación en los datos de prueba\n",
    "    accuracy_prueba = accuracy_score(y_test, predicciones_prueba)\n",
    "    precision_prueba = precision_score(y_test, predicciones_prueba, average='macro')\n",
    "    recall_prueba = recall_score(y_test, predicciones_prueba, average='macro')\n",
    "    f1_prueba = f1_score(y_test, predicciones_prueba, average='macro')\n",
    "\n",
    "    # Imprimir las métricas de evaluación en los datos de entrenamiento y de prueba\n",
    "    print(\"Accuracy en datos de entrenamiento:\", accuracy_entrenamiento)\n",
    "    print(\"Precision en datos de entrenamiento:\", precision_entrenamiento)\n",
    "    print(\"Recall en datos de entrenamiento:\", recall_entrenamiento)\n",
    "    print(\"F1-score en datos de entrenamiento:\", f1_entrenamiento)\n",
    "    print(\"Accuracy en datos de prueba:\", accuracy_prueba)\n",
    "    print(\"Precision en datos de prueba:\", precision_prueba)\n",
    "    print(\"Recall en datos de prueba:\", recall_prueba)\n",
    "    print(\"F1-score en datos de prueba:\", f1_prueba)\n",
    "\n",
    "    # Calcular la métrica a optimizar utilizando validación cruzada\n",
    "    metrica = cross_val_score(pipeline_estimador, X_train, y_train, scoring='accuracy', cv=5).mean()\n",
    "\n",
    "    # Devolver la métrica para ser maximizada por Optuna\n",
    "    return metrica\n",
    "\n",
    "# Crear el estudio de Optuna\n",
    "study = optuna.create_study(direction='maximize')\n",
    "\n",
    "# Realizar la optimización de hiperparámetros\n",
    "study.optimize(objective, n_trials=100)\n",
    "\n",
    "# Obtener los mejores hiperparámetros encontrados\n",
    "mejores_hiperparametros = study.best_params\n",
    "\n",
    "# Crear el pipeline con los mejores hiperparámetros encontrados\n",
    "pipeline_mejor = Pipeline([\n",
    "    (\"procesado_variables\", pipeline_procesado),\n",
    "    (\"estimador\", lgb.LGBMClassifier(**mejores_hiperparametros))\n",
    "])\n",
    "\n",
    "# Ajustar el pipeline al conjunto de entrenamiento\n",
    "pipeline_mejor.fit(X_train, y_train)\n",
    "\n",
    "# Calcular la exactitud obtenida con los mejores hiperparámetros en los datos de prueba\n",
    "exactitud_mejor = pipeline_mejor.score(X_test, y_test)\n",
    "\n",
    "# Imprimir los mejores hiperparámetros encontrados y la exactitud obtenida\n",
    "print(\"Mejores hiperparámetros encontrados:\", mejores_hiperparametros)\n",
    "print(\"Exactitud obtenida:\", exactitud_mejor)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "213ee160",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    # Definir los rangos de búsqueda de los hiperparámetros\n",
    "    params = {\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.1, log=True),\n",
    "        'reg_alpha': trial.suggest_float('reg_alpha', 1e-10, 1.0, log=True),\n",
    "        'reg_lambda': trial.suggest_float('reg_lambda', 1e-10, 1.0, log=True),\n",
    "        'num_leaves': trial.suggest_int('num_leaves', 10, 100),\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 10),\n",
    "        'min_child_samples': trial.suggest_int('min_child_samples', 1, 20),\n",
    "        'subsample': trial.suggest_float('subsample', 0.5, 1.0),\n",
    "        'scale_pos_weight': trial.suggest_float('scale_pos_weight', 0.1, 10.0),\n",
    "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 1.0),\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 100, 1000)\n",
    "    }\n",
    "\n",
    "    # Crear el pipeline con los hiperparámetros sugeridos por Optuna\n",
    "    pipeline_estimador = Pipeline([\n",
    "        (\"procesado_variables\", pipeline_procesado),\n",
    "        (\"estimador\", lgb.LGBMClassifier(**params))\n",
    "    ])\n",
    "\n",
    "    # Ajustar el pipeline al conjunto de entrenamiento\n",
    "    pipeline_estimador.fit(X_train, y_train)\n",
    "\n",
    "    # Realizar predicciones en los datos de entrenamiento\n",
    "    predicciones_entrenamiento = pipeline_estimador.predict(X_train)\n",
    "\n",
    "    # Calcular las métricas de evaluación en los datos de entrenamiento\n",
    "    accuracy_entrenamiento = accuracy_score(y_train, predicciones_entrenamiento)\n",
    "    precision_entrenamiento = precision_score(y_train, predicciones_entrenamiento, average='macro')\n",
    "    recall_entrenamiento = recall_score(y_train, predicciones_entrenamiento, average='macro')\n",
    "    f1_entrenamiento = f1_score(y_train, predicciones_entrenamiento, average='macro')\n",
    "\n",
    "    # Realizar predicciones en los datos de prueba\n",
    "    predicciones_prueba = pipeline_estimador.predict(X_test)\n",
    "\n",
    "    # Calcular las métricas de evaluación en los datos de prueba\n",
    "    accuracy_prueba = accuracy_score(y_test, predicciones_prueba)\n",
    "    precision_prueba = precision_score(y_test, predicciones_prueba, average='macro')\n",
    "    recall_prueba = recall_score(y_test, predicciones_prueba, average='macro')\n",
    "    f1_prueba = f1_score(y_test, predicciones_prueba, average='macro')\n",
    "\n",
    "    # Imprimir las métricas de evaluación en los datos de entrenamiento y de prueba\n",
    "    print(\"Accuracy en datos de entrenamiento:\", accuracy_entrenamiento)\n",
    "    print(\"Precision en datos de entrenamiento:\", precision_entrenamiento)\n",
    "    print(\"Recall en datos de entrenamiento:\", recall_entrenamiento)\n",
    "    print(\"F1-score en datos de entrenamiento:\", f1_entrenamiento)\n",
    "    print(\"Accuracy en datos de prueba:\", accuracy_prueba)\n",
    "    print(\"Precision en datos de prueba:\", precision_prueba)\n",
    "    print(\"Recall en datos de prueba:\", recall_prueba)\n",
    "    print(\"F1-score en datos de prueba:\", f1_prueba)\n",
    "\n",
    "    # Calcular la métrica a optimizar utilizando validación cruzada\n",
    "    metrica = cross_val_score(pipeline_estimador, X_train, y_train, scoring='accuracy', cv=5).mean()\n",
    "\n",
    "    # Devolver la métrica para ser maximizada por Optuna\n",
    "    return metrica\n",
    "\n",
    "# Crear el estudio de Optuna\n",
    "study = optuna.create_study(direction='maximize')\n",
    "\n",
    "# Realizar la optimización de hiperparámetros\n",
    "study.optimize(objective, n_trials=100)\n",
    "\n",
    "# Obtener los mejores hiperparámetros encontrados\n",
    "mejores_hiperparametros = study.best_params\n",
    "\n",
    "# Crear el pipeline con los mejores hiperparámetros encontrados\n",
    "pipeline_mejor = Pipeline([\n",
    "    (\"procesado_variables\", pipeline_procesado),\n",
    "    (\"estimador\", lgb.LGBMClassifier(**mejores_hiperparametros))\n",
    "])\n",
    "\n",
    "# Ajustar el pipeline al conjunto de entrenamiento\n",
    "pipeline_mejor.fit(X_train, y_train)\n",
    "\n",
    "# Calcular la exactitud obtenida con los mejores hiperparámetros en los datos de prueba\n",
    "exactitud_mejor = pipeline_mejor.score(X_test, y_test)\n",
    "\n",
    "# Imprimir los mejores hiperparámetros encontrados y la exactitud obtenida\n",
    "print(\"Mejores hiperparámetros encontrados:\", mejores_hiperparametros)\n",
    "print(\"Exactitud obtenida:\", exactitud_mejor)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb635940",
   "metadata": {},
   "source": [
    "### Finalmente, los mejores hiperparametros obtenidos son guardados en otro notebook donde se almacenan y ordenan para encontrar la mejor configuración de hiperparametros para el modelo LightGBM"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
